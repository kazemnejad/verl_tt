hydra:
  searchpath:
    - file://verl/trainer/config

defaults:
  - rollout@actor_rollout_ref.rollout: rollout
  - _self_

# === Trainer (hardware + output + logging) ===
trainer:
  n_gpus_per_node: 8
  nnodes: 1
  project_name: generation
  experiment_name: ${now:%Y%m%d_%H%M%S}
  default_local_dir: outputs/${trainer.project_name}/${trainer.experiment_name}
  logger: ["console", "wandb"]

# === Model ===
actor_rollout_ref:
  model:
    path: ???
    trust_remote_code: true
    dtype: bfloat16
  rollout:
    name: sglang
    tensor_model_parallel_size: 1
    data_parallel_size: 1
    pipeline_model_parallel_size: 1
    gpu_memory_utilization: 0.85
    temperature: 1.0
    top_p: 1.0
    top_k: -1
    prompt_length: 1024
    response_length: 4096
    agent:
      num_workers: 8
      default_agent_loop: single_turn_agent

# === Reward Model (disabled) ===
reward_model:
  enable: false
  use_reward_loop: false
  enable_resource_pool: false

# === Data ===
data:
  files: ???
  prompt_key: prompt
  max_samples: null
  return_raw_chat: true

# === Task System (optional) ===
tasks: null

# === Generation Runner ===
generation:
  save_batch_size: 1000
  pull_timeout: 30.0
  final_merge: true
  show_progress: true
  upload_artifact: true

# === Ray (optional) ===
ray_kwargs:
  ray_init: {}
  timeline_json_file: null
